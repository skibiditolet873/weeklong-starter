{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZBrrEyZOsn6"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "uHE7HhLZ6utW"
      },
      "outputs": [],
      "source": [
        "# basic imports for libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# model imports\n",
        "from sklearn.svm import SVC, SVR\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "from sklearn.linear_model import LogisticRegression, Ridge\n",
        "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "\n",
        "\n",
        "# evaluation and training imports\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, average_precision_score, mean_squared_error, r2_score, root_mean_squared_error, mean_absolute_percentage_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# preprocessing imports\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pc8sY5-5qOeZ"
      },
      "source": [
        "# Weeklong Project: Supervised Learning Model\n",
        "Welcome to the starter file for your weeklong project! This is an opportunity for you to work independently with a supervised learning model. There will not be much guidance in this file, so you should rely on [scikit-learn documentation](https://scikit-learn.org/stable/api/index.html) and the other files we've worked on this week for help. Feel free to add new cells and imports as needed.\n",
        "## Exploratory Data Analysis\n",
        "Get to know your data a little better, and start planning out preprocessing steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "-OKVxe4-JaZN"
      },
      "outputs": [],
      "source": [
        "data_root = \"https://github.com/rachelkd/geering-up/raw/refs/heads/main/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krj8ZRd26nLj",
        "outputId": "3e38b1b6-7fb0-4d29-9d94-fc7f8b5a62bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 801 entries, 0 to 800\n",
            "Data columns (total 41 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   abilities          801 non-null    object \n",
            " 1   against_bug        801 non-null    float64\n",
            " 2   against_dark       801 non-null    float64\n",
            " 3   against_dragon     801 non-null    float64\n",
            " 4   against_electric   801 non-null    float64\n",
            " 5   against_fairy      801 non-null    float64\n",
            " 6   against_fight      801 non-null    float64\n",
            " 7   against_fire       801 non-null    float64\n",
            " 8   against_flying     801 non-null    float64\n",
            " 9   against_ghost      801 non-null    float64\n",
            " 10  against_grass      801 non-null    float64\n",
            " 11  against_ground     801 non-null    float64\n",
            " 12  against_ice        801 non-null    float64\n",
            " 13  against_normal     801 non-null    float64\n",
            " 14  against_poison     801 non-null    float64\n",
            " 15  against_psychic    801 non-null    float64\n",
            " 16  against_rock       801 non-null    float64\n",
            " 17  against_steel      801 non-null    float64\n",
            " 18  against_water      801 non-null    float64\n",
            " 19  attack             801 non-null    int64  \n",
            " 20  base_egg_steps     801 non-null    int64  \n",
            " 21  base_happiness     801 non-null    int64  \n",
            " 22  base_total         801 non-null    int64  \n",
            " 23  capture_rate       801 non-null    object \n",
            " 24  classfication      801 non-null    object \n",
            " 25  defense            801 non-null    int64  \n",
            " 26  experience_growth  801 non-null    int64  \n",
            " 27  height_m           781 non-null    float64\n",
            " 28  hp                 801 non-null    int64  \n",
            " 29  japanese_name      801 non-null    object \n",
            " 30  name               801 non-null    object \n",
            " 31  percentage_male    703 non-null    float64\n",
            " 32  pokedex_number     801 non-null    int64  \n",
            " 33  sp_attack          801 non-null    int64  \n",
            " 34  sp_defense         801 non-null    int64  \n",
            " 35  speed              801 non-null    int64  \n",
            " 36  type1              801 non-null    object \n",
            " 37  type2              417 non-null    object \n",
            " 38  weight_kg          781 non-null    float64\n",
            " 39  generation         801 non-null    int64  \n",
            " 40  is_legendary       801 non-null    int64  \n",
            "dtypes: float64(21), int64(13), object(7)\n",
            "memory usage: 256.7+ KB\n"
          ]
        }
      ],
      "source": [
        "# TODO: Uncomment one of these lines to select a dataset\n",
        "poke_data = pd.read_csv(data_root + \"data/pokemon.csv\")\n",
        "# cereal_data = pd.read_csv(data_root + \"data/cereal.csv\")\n",
        "# penguin_data = pd.read_csv(data_root + \"data/penguins_size.csv\")\n",
        "poke_data.info()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Em6wTYbFqZma"
      },
      "source": [
        "## Splitting Data\n",
        "Identify your features and target, and split your data into training and testing sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "1qj0aqsqJaZN",
        "outputId": "c3387011-8280-4b43-885a-c6d9db596cac"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"['base_egg_stats'] not found in axis\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-87-1689423665.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Select features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpoke_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"generation\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"japanese_name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"capture_rate\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"base_egg_stats\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfeature_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpoke_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'against_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoke_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5579\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5580\u001b[0m         \"\"\"\n\u001b[0;32m-> 5581\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   5582\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5583\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4786\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4787\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4788\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4790\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4828\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4829\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4830\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4831\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7068\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7069\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7070\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask].tolist()} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7071\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7072\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['base_egg_stats'] not found in axis\""
          ]
        }
      ],
      "source": [
        "# Select features\n",
        "poke_data.drop(columns=[\"generation\", \"japanese_name\", \"capture_rate\", \"base_egg_steps\"])\n",
        "\n",
        "feature_columns = [col for col in poke_data.columns if not col.startswith('against_')]\n",
        "features = poke_data[feature_columns]\n",
        "# Select target columns\n",
        "target_columns = [col for col in poke_data.columns if col.startswith('against_')]\n",
        "target = poke_data[target_columns]\n",
        "\n",
        "print(\"Features shape:\", features.shape)\n",
        "print(\"Target shape:\", target.shape)\n",
        "\n",
        "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Features train shape:\", features_train.shape)\n",
        "print(\"Features test shape:\", features_test.shape)\n",
        "print(\"Target train shape:\", target_train.shape)\n",
        "print(\"Target test shape:\", target_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYnCXax0JaZO"
      },
      "source": [
        "## Preprocessing\n",
        "Preprocess your data, keeping in mind the golden rule."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsVQWpuGJaZO"
      },
      "outputs": [],
      "source": [
        "# Identify categorical and numerical columns\n",
        "categorical_features = features.select_dtypes(include=['object', 'category']).columns\n",
        "numerical_features = features.select_dtypes(include=np.number).columns\n",
        "\n",
        "print(\"Categorical features:\", categorical_features)\n",
        "print(\"Numerical features:\", numerical_features)\n",
        "\n",
        "# Create transformers for numerical and categorical features\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Create a column transformer to apply different transformations to different columns\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "# Fit the preprocessor on the training data\n",
        "features_train_processed = preprocessor.fit_transform(features_train)\n",
        "\n",
        "# Transform the test data\n",
        "features_test_processed = preprocessor.transform(features_test)\n",
        "\n",
        "print(\"Processed features train shape:\", features_train_processed.shape)\n",
        "print(\"Processed features test shape:\", features_test_processed.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytskQtBiJaZO"
      },
      "source": [
        "## Training and Testing\n",
        "Choose an evaluation metric to score your models on. Then, train and optimize the hyperparameters for at least 3 different models and see which one works best.\n",
        "\n",
        "If you've chosen a **classification problem**, your metric could be:\n",
        "- Accuracy (default)\n",
        "- Precision\n",
        "- Recall\n",
        "- F1 score\n",
        "- ROC AUC\n",
        "- etc...\n",
        "\n",
        "Your models could be:\n",
        "- `SVC` (linear or RBF)\n",
        "- `KNeighborsClassifier`\n",
        "- `DecisionTreeClassifier`\n",
        "- `LogisticRegression`\n",
        "- `RandomForestClassifier`\n",
        "- etc...\n",
        "\n",
        "If you've chosen a **regression problem**, your metric could be:\n",
        "- R^2 score (default)\n",
        "- Mean squared error (MSE) /root of mean squared error (RMSE)\n",
        "- Mean absolute percentage error (MAPE)\n",
        "- etc...\n",
        "\n",
        "Your models could be:\n",
        "- `SVR` (linear and/or RBF)\n",
        "- `KNeighborsRegressor`\n",
        "- `DecisionTreeRegressor`\n",
        "- `Ridge` (linear model)\n",
        "- `RandomForestRegressor`\n",
        "- etc..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqke_CvYJaZO"
      },
      "outputs": [],
      "source": [
        "# Initialize multi-output regression models\n",
        "# DecisionTreeRegressor and RandomForestRegressor support multi-output natively\n",
        "dt_regressor = DecisionTreeRegressor(random_state=42)\n",
        "rf_regressor = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Ridge and KNeighborsRegressor do not natively support multi-output, so we wrap them\n",
        "ridge_regressor = MultiOutputRegressor(Ridge())\n",
        "knn_regressor = MultiOutputRegressor(KNeighborsRegressor())\n",
        "\n",
        "\n",
        "models = {\n",
        "    \"Decision Tree Regressor\": dt_regressor,\n",
        "    \"Random Forest Regressor\": rf_regressor,\n",
        "    \"Ridge Regressor\": ridge_regressor,\n",
        "    \"KNeighbors Regressor\": knn_regressor\n",
        "}\n",
        "\n",
        "# Set the name of the model you want to train\n",
        "selected_model_name = \"Random Forest Regressor\" # Changed to Random Forest Regressor\n",
        "\n",
        "# Define hyperparameters for the selected model\n",
        "# This is an example for RandomForestRegressor\n",
        "hyperparameters = {\n",
        "    'n_estimators': 200, # Number of trees\n",
        "    'max_depth': 20, # Maximum depth of trees\n",
        "    'min_samples_split': 5, # Minimum samples required to split\n",
        "    'min_samples_leaf': 2, # Minimum samples at a leaf node\n",
        "    'max_features': 'sqrt' # Number of features to consider for splits\n",
        "}\n",
        "\n",
        "# # Select model\n",
        "# selected_model_name = \"KNeighbors Regressor\"\n",
        "\n",
        "# # Define hyperparameters\n",
        "# hyperparameters = {\n",
        "#     'estimator__n_neighbors': 7,\n",
        "#     'estimator__weights': 'distance'\n",
        "# }\n",
        "\n",
        "\n",
        "# Train the selected model\n",
        "model = models[selected_model_name]\n",
        "print(f\"Training {selected_model_name}...\")\n",
        "model.set_params(**hyperparameters)\n",
        "model.fit(features_train_processed, target_train)\n",
        "print(\"Training complete.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmXUYcHXJaZO"
      },
      "source": [
        "## Final Report\n",
        "Report your best model's metric. How do you feel about this score? Is there anything you could change?\n",
        "\n",
        "If you have time, prepare a presentation or report discussing:\n",
        "- Which dataset you picked\n",
        "- What preprocessing you had to do\n",
        "- Which columns you dropped, if any\n",
        "- Which 3 models you chose\n",
        "- Which evaluation metric(s) you chose\n",
        "- What hyperparameter tuning was like\n",
        "- Which model performed the best\n",
        "- Your opinion on the best model's predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46af8dc2"
      },
      "source": [
        "# Evaluate the models using R-squared as the metric\n",
        "# Using model.score() which returns R-squared for regressors\n",
        "from sklearn.metrics import r2_score # Still need this for the explicit r2_score calculation in case model.score() isn't available or for clarity\n",
        "\n",
        "\n",
        "# Only evaluate the selected model\n",
        "if selected_model_name in models:\n",
        "    model = models[selected_model_name]\n",
        "    # Use the score method, which returns R-squared for regressors\n",
        "    r2 = model.score(features_test_processed, target_test)\n",
        "else:\n",
        "    print(f\"Model '{selected_model_name}' not found in the models dictionary.\")\n",
        "\n",
        "\n",
        "# Print the results\n",
        "print(f\"\\nModel Evaluation Results: {r2}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dea11bb9"
      },
      "source": [
        "## Inspecting Predictions\n",
        "Inspect the actual and predicted values for a few test samples to understand the model's performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c63ead42"
      },
      "source": [
        "# Make predictions on the test set\n",
        "predictions = model.predict(features_test_processed)\n",
        "\n",
        "# Select the first few test samples\n",
        "n_samples_to_show = 3\n",
        "\n",
        "# Display the actual target values and the predictions\n",
        "print(\"Actual target values for the first\", n_samples_to_show, \"test samples:\")\n",
        "display(target_test.head(n_samples_to_show))\n",
        "\n",
        "print(\"\\nPredicted values for the first\", n_samples_to_show, \"test samples:\")\n",
        "# We use a DataFrame for predictions to have the same structure as the target\n",
        "predictions_df = pd.DataFrame(predictions, columns=target_test.columns, index=target_test.index)\n",
        "display(predictions_df.head(n_samples_to_show))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "WZBrrEyZOsn6"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}